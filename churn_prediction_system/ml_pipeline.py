# -*- coding: utf-8 -*-
"""ML_pipeline

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1J6YeyB_UKioqHOZ4DXpG4QjyAeu5Ol_x
"""

import pandas as pd

df = pd.read_csv('BankChurners.csv')
df.head()

df.columns

df.drop(columns=['CLIENTNUM','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2' ], inplace=True)

df.columns

df.columns = df.columns.str.lower()
df.columns

df.info()

df['gender'].unique()

df['education_level'].unique()

df['marital_status'].unique()

df['income_category'].unique()

df['card_category'].unique()

num_cols = ['months_on_book', 'total_relationship_count', 'months_inactive_12_mon',
       'contacts_count_12_mon', 'credit_limit', 'total_revolving_bal',
       'avg_open_to_buy', 'total_amt_chng_q4_q1', 'total_trans_amt',
       'total_trans_ct', 'total_ct_chng_q4_q1', 'avg_utilization_ratio']

for col in num_cols:
  print(f'\nfor the column {col}:')
  print(df[col].describe())

df['attrition_flag'].unique()

X = df.drop(columns=['attrition_flag'])
X.columns

y = df['attrition_flag']

X.info()

y.info()

y = y.str.strip().str.lower()

y.unique()

y = y.replace({'attrited customer': 1, 'existing customer':0})

y.unique()

"""# **Pipeline**"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

"""## Categorical pipelines"""

from preprocessing import TextStandardizer

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder

cat_pipeline_1 = Pipeline([
    ("text_standardize", TextStandardizer()),
    ("onehot", OneHotEncoder(handle_unknown="ignore",sparse_output=False))])

education_order = ['unknown', 'uneducated','high school','college' ,'graduate','post-graduate', 'doctorate']

income_order = ["unknown","less than $40k","$40k - $60k","$60k - $80k","$80k - $120k", "$120k +"]

card_order = ["blue", "silver","gold","platinum"]

from sklearn.preprocessing import OrdinalEncoder
cat_pipeline_2 = Pipeline([
      ("text_standardize", TextStandardizer()),
      ("ordinal_encode", OrdinalEncoder(categories=[education_order, income_order, card_order], handle_unknown="use_encoded_value", unknown_value=-1))])

num_pipeline = Pipeline([
    ("select", "passthrough")
])

from sklearn.compose import ColumnTransformer
col_transformer = ColumnTransformer(
    transformers=[
        ('num_pip', num_pipeline, ['customer_age', 'dependent_count', 'months_on_book', 'total_relationship_count', 'months_inactive_12_mon', 'contacts_count_12_mon', 'credit_limit', 'total_revolving_bal', 'avg_open_to_buy', 'total_amt_chng_q4_q1', 'total_trans_amt', 'total_trans_ct', 'total_ct_chng_q4_q1', 'avg_utilization_ratio']),
	      ('cat_pip_1', cat_pipeline_1, ['gender', 'marital_status']),
        ('cat_pip_2', cat_pipeline_2, ['education_level', 'income_category', 'card_category'])
    ],
    remainder='drop'
)

from xgboost import XGBClassifier

xgb_model = XGBClassifier(
    random_state=42,
    n_estimators=300,
    learning_rate=0.1,
    max_depth=6,
    subsample=0.8,
    colsample_bytree=0.8,
    scale_pos_weight=(len(y_train[y_train == 0]) / len(y_train[y_train == 1])),
    tree_method="hist",
    eval_metric="logloss"
)

full_pipeline = Pipeline([
    ("preprocess", col_transformer),
    ("model", xgb_model)
])

full_pipeline.fit(X_train, y_train)
full_pipeline.predict(X_test)

from sklearn.metrics import classification_report, roc_auc_score

y_pred = full_pipeline.predict(X_test)

print(classification_report(y_test, y_pred))

y_proba = full_pipeline.predict_proba(X_test)[:, 1]
print("ROC AUC:", roc_auc_score(y_test, y_proba))

import joblib
joblib.dump(full_pipeline, "xgb_churn_pipeline.pkl")